{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZnyMciU1eBlsJkb3omvoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gloguercio/cloth_classifier/blob/main/DeepLearning_Track.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDheAX0dcYNC"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import opendatasets as od\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import BatchNormalization ,GlobalMaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping ,ReduceLROnPlateau ,ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset from Kaggle (assuming `od` is properly imported)\n",
        "od.download('https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small',data_dir=\"dataset\")"
      ],
      "metadata": {
        "id": "njG5Ga8CeVX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file containing information about fashion products into a Pandas DataFrame\n",
        "clothes_df = pd.read_csv('dataset/fashion-product-images-small/styles.csv', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "2pfemdc1eQ7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "clothes_df.head()"
      ],
      "metadata": {
        "id": "R1TfTUQWeRAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing values\n",
        "clothes_df = clothes_df.dropna()"
      ],
      "metadata": {
        "id": "so9pwsG8eROG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of unique values in each column\n",
        "clothes_df.nunique()"
      ],
      "metadata": {
        "id": "gcPw45cdeNkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names\n",
        "clothes_df.columns"
      ],
      "metadata": {
        "id": "Ar_dnhwseIPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine different categorical columns into one for creating labels\n",
        "clothes_df['combined_category'] = clothes_df['articleType'] + '_' + clothes_df['baseColour'] + '_' + clothes_df['masterCategory'] + '_' + clothes_df['subCategory']"
      ],
      "metadata": {
        "id": "d4doISJkeITL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the length of the DataFrame after data cleaning\n",
        "len(clothes_df)"
      ],
      "metadata": {
        "id": "3Zq-iSKjeIWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store image data\n",
        "data = []"
      ],
      "metadata": {
        "id": "xagYpNEveEDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each product ID and process its associated image\n",
        "for name in clothes_df.id:\n",
        "    try:\n",
        "        # Read the image\n",
        "        image = cv2.imread('dataset/fashion-product-images-small/images/'+str(name)+'.jpg')\n",
        "        # Resize the image to a fixed size\n",
        "        image = cv2.resize(image, (IX,IY) )\n",
        "        # Convert the image to a NumPy array\n",
        "        image = img_to_array(image)\n",
        "        # Append the image data to the list\n",
        "        data.append(image)\n",
        "    except:\n",
        "        # Skip images for which there are errors in loading\n",
        "        invalid_ids.append(name)"
      ],
      "metadata": {
        "id": "Y25dbIH9eEHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store labels\n",
        "labels = []"
      ],
      "metadata": {
        "id": "w7WS6YMZd9R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each row in the DataFrame to extract labels\n",
        "for index, row in clothes_df.iterrows():\n",
        "    if row['id'] in invalid_ids:\n",
        "        continue\n",
        "    tags = []\n",
        "    for col in used_column:\n",
        "        tags.append(row[col])\n",
        "    labels.append(tags)"
      ],
      "metadata": {
        "id": "5YM_OO7id9Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the lists to NumPy arrays\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "cKzherfmd6MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the extracted labels\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "41B-Vd6Ndz1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels using MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(labels)"
      ],
      "metadata": {
        "id": "OSpOsx0qdz4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classes learned by the MultiLabelBinarizer\n",
        "print(mlb.classes_)\n",
        "print(labels[0])"
      ],
      "metadata": {
        "id": "uqjTV0oMd0Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape for the model\n",
        "inputShape = (60, 80, 3)"
      ],
      "metadata": {
        "id": "fj0HaP8-dtHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture of the neural network model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape),\n",
        "    Activation(\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(64, (3, 3)),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='sigmoid'),\n",
        "    Dense(labels.shape[1], activation='sigmoid')  # Output layer with the number of unique combined categories\n",
        "])"
      ],
      "metadata": {
        "id": "BCADpHcpdtW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CxlwIseEdtdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "Ajw8HB_OdofY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size\n",
        "batch = 32"
      ],
      "metadata": {
        "id": "p6PZZGlAdojV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x=trainX, y=trainY, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "SbSgMNKWdbsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "preds = model.predict(testX)"
      ],
      "metadata": {
        "id": "88f8S4xKdesN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "accuracy = model.evaluate(testX, testY, verbose=0)[1]\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "UnCNbCADdevX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the binarized labels\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "vHAPh3s9dbxO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}